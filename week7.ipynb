{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb50d30",
   "metadata": {},
   "source": [
    "# Week 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01306356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Using cached surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
      "Collecting scikit-surprise (from surprise)\n",
      "  Using cached scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [44 lines of output]\n",
      "      Compiling surprise/similarities.pyx because it changed.\n",
      "      Compiling surprise/prediction_algorithms/matrix_factorization.pyx because it changed.\n",
      "      Compiling surprise/prediction_algorithms/optimize_baselines.pyx because it changed.\n",
      "      Compiling surprise/prediction_algorithms/slope_one.pyx because it changed.\n",
      "      Compiling surprise/prediction_algorithms/co_clustering.pyx because it changed.\n",
      "      [1/5] Cythonizing surprise/prediction_algorithms/co_clustering.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              self.avg_cltr_i = avg_cltr_i\n",
      "              self.avg_cocltr = avg_cocltr\n",
      "      \n",
      "              return self\n",
      "      \n",
      "          def compute_averages(self, np.ndarray[np.int_t] cltr_u,\n",
      "                                                   ^\n",
      "      ------------------------------------------------------------\n",
      "      surprise\\prediction_algorithms\\co_clustering.pyx:157:45: Invalid type.\n",
      "      Traceback (most recent call last):\n",
      "        File \u001b[35m\"c:\\Users\\armin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\Users\\armin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\Users\\armin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return hook(config_settings)\n",
      "        File \u001b[35m\"C:\\Users\\armin\\AppData\\Local\\Temp\\pip-build-env-fd6zg2v2\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m333\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\armin\\AppData\\Local\\Temp\\pip-build-env-fd6zg2v2\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\armin\\AppData\\Local\\Temp\\pip-build-env-fd6zg2v2\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m116\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\armin\\AppData\\Local\\Temp\\pip-build-env-fd6zg2v2\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\"\u001b[0m, line \u001b[35m1153\u001b[0m, in \u001b[35mcythonize\u001b[0m\n",
      "          \u001b[31mcythonize_one\u001b[0m\u001b[1;31m(*args)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\armin\\AppData\\Local\\Temp\\pip-build-env-fd6zg2v2\\overlay\\Lib\\site-packages\\Cython\\Build\\Dependencies.py\"\u001b[0m, line \u001b[35m1297\u001b[0m, in \u001b[35mcythonize_one\u001b[0m\n",
      "          raise CompileError(None, pyx_file)\n",
      "      \u001b[1;35mCython.Compiler.Errors.CompileError\u001b[0m: \u001b[35msurprise/prediction_algorithms/co_clustering.pyx\u001b[0m\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f606503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f75ab37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_parquet('test_video_games.parquet')\n",
    "train_df = pd.read_parquet('train_video_games.parquet')\n",
    "items_highly_rated_freq = pd.read_csv('item_highly_rated_freq.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be2917",
   "metadata": {},
   "source": [
    "Based on the frequency of the most rated items computed in Week 6,\n",
    "implement the TopPop Recommender System, which always recommends\n",
    "the same top-k items sorted decreasingly by the number of “high” ratings\n",
    "(e.g., → 3) in the training split (train video games.parquet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "527090bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      item_id  highly_rated_count  average_rating_by_item\n",
      "0  B0086VPUHI                 154                4.425150\n",
      "1  B00BN5T30E                 150                4.428571\n",
      "2  B07YBXFDYN                 146                4.329268\n",
      "3  B00BGA9WK2                 136                4.432432\n",
      "4  B007CM0K86                 123                4.554688\n",
      "5  B00KIWEMIG                 109                4.237705\n",
      "6  B07YBWT3PK                 104                4.107438\n",
      "7  B07YBXFF99                 103                4.345455\n",
      "8  B014R4KYMS                 102                4.532110\n",
      "9  B004HD55VK                 102                4.615385\n"
     ]
    }
   ],
   "source": [
    "# implement based line TopPop recommender system\n",
    "top_pop_items = items_highly_rated_freq.head(10)\n",
    "# just recommend the top 10 most popular highly rated (defined as having a rating >= 3) items\n",
    "print(top_pop_items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743e7ad1",
   "metadata": {},
   "source": [
    "Choose at least one neighborhood-based model and one latent factor model (both type of colaborative filtering)\n",
    "that uses the observed user-item ratings in the training set to predict the\n",
    "unobserved ratings. Report your choice of models.   \n",
    "\n",
    "Does unobserved mean empty cell? There is no missing data as seen in from the data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5520b6",
   "metadata": {},
   "source": [
    "Use 5-fold cross-validation on the training set to tune the hyperparameters\n",
    "of the chosen models (similarity measure and number of neighbors for the\n",
    "neighborhood-based model; number of latent factors and number of epochs\n",
    "for the latent factor model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe56377",
   "metadata": {},
   "source": [
    "Choose an evaluation measure that is suitable for this task and justify your\n",
    "motivation in using it. Report the optimal hyperparameters together with\n",
    "the scores of your chosen measure, averaged over the 5 folds.\n",
    "• Run the models with the optimal hyperparameters to the whole training\n",
    "set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c98833d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert train and test to csv files\n",
    "train_df.to_csv('train_video_games.csv', index=False)\n",
    "test_df.to_csv('test_video_games.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32603b97",
   "metadata": {},
   "source": [
    "### Item Based KNN Colaborative Filtering\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469140dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create item based KNN colaborative filtering recommender system using the surprise library\n",
    "# use 5-fold cross validation \n",
    "# use Root Mean Square Error (RMSE) as the evaluation metric\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import KNNBasic, KNNBaseline\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "\n",
    "# load the data into surprise format\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/evaluate the algorithm using grind search 5 fold cross validation\n",
    "params = {'num_neighbors':[5, 10, 20], 'epochs':[5, 10, 15], 'sim_options': {'name': ['cosine', 'pearson'], 'user_based': [False]}}\n",
    "algo = KNNBaseline()\n",
    "cv_results = GridSearchCV(algo, params, cv=5)\n",
    "\n",
    "# print the average RMSE\n",
    "print(f\"Average RMSE: {np.mean(cv_results['test_rmse'])}\")\n",
    "# np mean is root mean square error?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deebb2a",
   "metadata": {},
   "source": [
    "### SVD \n",
    "SVD is a matrix factorization technique that decomposes the user-item interaction matrix into latent factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8cd22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a SVD based collabortative filtering recommender system using the surprise library\n",
    "from surprise import SVD\n",
    "\n",
    "algoSVD = SVD()\n",
    "\n",
    "# data and reader is the same \n",
    "# hyperparameters for SVD can be tuned using grid search\n",
    "params_svd = {'n_factors': [50, 100, 150], 'n_epochs': [20, 30, 40], 'lr_all': [0.002, 0.005, 0.01], 'reg_all': [0.02, 0.05, 0.1]}\n",
    "cv_results_svd = GridSearchCV(SVD, params_svd, cv=5)\n",
    "cv_results_svd.fit(data)\n",
    "\n",
    "# print the average RMSE\n",
    "print(f\"Average RMSE for SVD: {np.mean(cv_results_svd['test_rmse'])}\")  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
